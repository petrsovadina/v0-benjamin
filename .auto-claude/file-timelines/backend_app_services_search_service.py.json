{
  "file_path": "backend/app/services/search_service.py",
  "main_branch_history": [],
  "task_views": {
    "001-complete-guidelines-rag-pdf-import": {
      "task_id": "001-complete-guidelines-rag-pdf-import",
      "branch_point": {
        "commit_hash": "d092d181e511c0ef7a36dcfd2dfe3f083cbae73e",
        "content": "",
        "timestamp": "2025-12-25T01:35:52.079046"
      },
      "worktree_state": {
        "content": "import json\nimport logging\nfrom paper_search_mcp.academic_platforms.pubmed import PubMedSearcher\nfrom backend.app.core.database import get_supabase_client\nfrom typing import List, Dict, Any\n\nlogger = logging.getLogger(\"search_service\")\n\nclass SearchService:\n    def __init__(self):\n        self.pubmed = PubMedSearcher()\n        \n    async def search_drugs(self, query: str, limit: int = 20) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search S\u00daKL data via Supabase (Semantic + Keyword fallback).\n        \"\"\"\n        supabase = get_supabase_client()\n        \n        # 1. semantic search (if configured)\n        try:\n             import os\n             if os.getenv(\"OPENAI_API_KEY\"):\n                 from backend.data_processing.generators.embedding_generator import EmbeddingGenerator\n                 emb_gen = EmbeddingGenerator()\n                 # Generate embedding for the query\n                 vecs = emb_gen.generate_embeddings([query])\n                 if vecs and vecs[0]:\n                     response = supabase.rpc(\"search_drugs\", {\n                         \"query_embedding\": vecs[0],\n                         \"match_threshold\": 0.5,\n                         \"match_count\": limit\n                     }).execute()\n                     if response.data:\n                         return response.data\n        except Exception as e:\n             logger.warning(f\"Semantic search failed (falling back to simple search): {e}\")\n\n        # 2. simple keyword search fallback\n        try:\n            # Note: Checking both name and active_substances\n            response = supabase.table(\"drugs\").select(\"*\").or_(f\"name.ilike.%{query}%,active_substances.ilike.%{query}%\").limit(limit).execute()\n            return response.data\n        except Exception as e:\n            logger.error(f\"S\u00daKL simple search error: {e}\")\n            return []\n\n    async def search_pubmed(self, query: str, max_results: int = 5) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search PubMed using paper-search-mcp logic.\n        \"\"\"\n        try:\n            # Calling synchronous library method\n            papers = self.pubmed.search(query, max_results)\n            \n            results = []\n            for p in papers:\n                p_data = {\n                    \"title\": p.title,\n                    \"url\": p.url,\n                    \"abstract\": p.abstract,\n                    \"authors\": p.authors,\n                    \"year\": p.published_date.year if p.published_date else None,\n                    \"pmid\": p.paper_id,\n                    \"doi\": p.doi,\n                    \"source\": \"pubmed\"\n                }\n                results.append(p_data)\n            return results\n        except Exception as e:\n            logger.error(f\"PubMed search error: {e}\")\n            return []\n            \n    async def search_guidelines(self, query: str, limit: int = 5, match_threshold: float = 0.7) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search Guidelines via Supabase using vector similarity search.\n\n        Args:\n            query: Search query text\n            limit: Maximum number of results to return (default: 5)\n            match_threshold: Minimum similarity threshold (default: 0.7)\n\n        Returns:\n            List of guideline chunks with metadata for citations\n        \"\"\"\n        import os\n        supabase = get_supabase_client()\n\n        # 1. Vector similarity search (requires OpenAI API key)\n        try:\n            if os.getenv(\"OPENAI_API_KEY\"):\n                from backend.data_processing.generators.embedding_generator import EmbeddingGenerator\n                emb_gen = EmbeddingGenerator()\n                # Generate embedding for the query\n                vecs = emb_gen.generate_embeddings([query])\n                if vecs and vecs[0]:\n                    response = supabase.rpc(\"match_guidelines\", {\n                        \"query_embedding\": vecs[0],\n                        \"match_threshold\": match_threshold,\n                        \"match_count\": limit\n                    }).execute()\n\n                    if response.data:\n                        # Format results with citation metadata\n                        results = []\n                        for item in response.data:\n                            metadata = item.get(\"metadata\", {})\n                            result = {\n                                \"id\": item.get(\"id\"),\n                                \"title\": item.get(\"title\"),\n                                \"content\": item.get(\"content\"),\n                                \"source\": metadata.get(\"source\", item.get(\"title\")),\n                                \"page\": metadata.get(\"page\"),\n                                \"similarity\": item.get(\"similarity\"),\n                                \"source_type\": \"guidelines\"\n                            }\n                            results.append(result)\n                        return results\n        except Exception as e:\n            logger.warning(f\"Guidelines semantic search failed: {e}\", extra={\n                \"step\": \"semantic_search\",\n                \"error\": str(e)\n            })\n\n        # 2. Keyword search fallback (if semantic search fails or no API key)\n        try:\n            response = supabase.table(\"guidelines\").select(\n                \"id, title, content, metadata\"\n            ).ilike(\"content\", f\"%{query}%\").limit(limit).execute()\n\n            if response.data:\n                results = []\n                for item in response.data:\n                    metadata = item.get(\"metadata\", {})\n                    result = {\n                        \"id\": item.get(\"id\"),\n                        \"title\": item.get(\"title\"),\n                        \"content\": item.get(\"content\"),\n                        \"source\": metadata.get(\"source\", item.get(\"title\")),\n                        \"page\": metadata.get(\"page\"),\n                        \"similarity\": None,\n                        \"source_type\": \"guidelines\"\n                    }\n                    results.append(result)\n                return results\n        except Exception as e:\n            logger.error(f\"Guidelines keyword search error: {e}\", extra={\n                \"step\": \"keyword_search\",\n                \"error\": str(e)\n            })\n\n        return []\n\nsearch_service = SearchService()\n",
        "last_modified": "2025-12-25T21:22:14.867275"
      },
      "task_intent": {
        "title": "001-complete-guidelines-rag-pdf-import",
        "description": "",
        "from_plan": false
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2025-12-25T01:36:12.857774",
  "last_updated": "2025-12-25T01:36:12.879330"
}