{
  "file_path": "backend/app/api/v1/endpoints/admin.py",
  "main_branch_history": [],
  "task_views": {
    "001-complete-guidelines-rag-pdf-import": {
      "task_id": "001-complete-guidelines-rag-pdf-import",
      "branch_point": {
        "commit_hash": "d092d181e511c0ef7a36dcfd2dfe3f083cbae73e",
        "content": "",
        "timestamp": "2025-12-25T01:35:52.079046"
      },
      "worktree_state": {
        "content": "import shutil\nimport os\nfrom datetime import datetime, timezone\nfrom typing import List, Dict, Any, Optional\nfrom fastapi import APIRouter, File, UploadFile, HTTPException, BackgroundTasks, Depends\nfrom backend.services.logger import get_logger\nfrom backend.services.sukl_api_client import SuklApiClient\nfrom backend.data_processing.loaders.guidelines_loader import GuidelinesLoader\n\nrouter = APIRouter()\nlogger = get_logger(__name__)\n\n\ndef create_error_detail(\n    code: str,\n    message: str,\n    context: Optional[Dict[str, Any]] = None\n) -> Dict[str, Any]:\n    \"\"\"\n    Create a structured error detail for HTTPException responses.\n\n    Args:\n        code: Error code identifier (e.g., \"INVALID_FILE_TYPE\", \"FILE_TOO_LARGE\")\n        message: Human-readable error message\n        context: Additional context about the error (optional)\n\n    Returns:\n        Structured error detail dictionary\n    \"\"\"\n    error_detail = {\n        \"error_code\": code,\n        \"message\": message,\n        \"timestamp\": datetime.now(timezone.utc).isoformat().replace(\"+00:00\", \"Z\"),\n    }\n\n    if context:\n        error_detail[\"context\"] = context\n\n    return error_detail\n\nUPLOAD_DIR = \"backend/data/guidelines_pdfs\"\nos.makedirs(UPLOAD_DIR, exist_ok=True)\n\n# Maximum file size: 50MB in bytes\nMAX_FILE_SIZE = 50 * 1024 * 1024\n\nasync def run_ingestion_task():\n    \"\"\"\n    Background task to run the ingestion pipeline.\n    \"\"\"\n    logger.info(\"Starting background ingestion task...\")\n    loader = GuidelinesLoader(pdf_dir=UPLOAD_DIR)\n    await loader.ingest_pdfs()\n    logger.info(\"Background ingestion task finished.\")\n\n@router.post(\"/upload/guideline\")\nasync def upload_guideline(\n    background_tasks: BackgroundTasks,\n    file: UploadFile = File(...)\n):\n    \"\"\"\n    Upload a PDF file to the guidelines knowledge base.\n    The file is saved and indexed in the background.\n    \"\"\"\n    if not file.filename.endswith(\".pdf\"):\n        file_extension = os.path.splitext(file.filename)[1] if file.filename else \"unknown\"\n        logger.warning(\n            \"Invalid file type uploaded\",\n            filename=file.filename,\n            extension=file_extension,\n            endpoint=\"/upload/guideline\"\n        )\n        raise HTTPException(\n            status_code=400,\n            detail=create_error_detail(\n                code=\"INVALID_FILE_TYPE\",\n                message=\"Only PDF files are supported.\",\n                context={\n                    \"filename\": file.filename,\n                    \"provided_extension\": file_extension,\n                    \"allowed_extensions\": [\".pdf\"]\n                }\n            )\n        )\n\n    # Read file content to check size\n    content = await file.read()\n    file_size = len(content)\n\n    if file_size > MAX_FILE_SIZE:\n        file_size_mb = file_size / (1024 * 1024)\n        max_size_mb = MAX_FILE_SIZE / (1024 * 1024)\n        logger.warning(\n            \"File size exceeds limit\",\n            filename=file.filename,\n            file_size_bytes=file_size,\n            file_size_mb=round(file_size_mb, 2),\n            max_size_mb=max_size_mb,\n            endpoint=\"/upload/guideline\"\n        )\n        raise HTTPException(\n            status_code=400,\n            detail=create_error_detail(\n                code=\"FILE_TOO_LARGE\",\n                message=f\"File size exceeds maximum allowed size of {max_size_mb:.0f}MB.\",\n                context={\n                    \"filename\": file.filename,\n                    \"file_size_bytes\": file_size,\n                    \"file_size_mb\": round(file_size_mb, 2),\n                    \"max_size_bytes\": MAX_FILE_SIZE,\n                    \"max_size_mb\": max_size_mb\n                }\n            )\n        )\n\n    file_path = os.path.join(UPLOAD_DIR, file.filename)\n\n    try:\n        with open(file_path, \"wb\") as buffer:\n            buffer.write(content)\n            \n        logger.info(\n            \"File saved successfully\",\n            filename=file.filename,\n            file_path=file_path,\n            file_size_bytes=file_size,\n            endpoint=\"/upload/guideline\"\n        )\n        \n        # Trigger ingestion in background\n        background_tasks.add_task(run_ingestion_task)\n        \n        return {\n            \"filename\": file.filename, \n            \"status\": \"uploaded\", \n            \"message\": \"File uploaded successfully. Indexing started in background.\"\n        }\n        \n    except Exception as e:\n        logger.error(\n            \"File upload failed\",\n            error=e,\n            filename=file.filename,\n            file_path=file_path,\n            file_size_bytes=file_size,\n            endpoint=\"/upload/guideline\"\n        )\n        raise HTTPException(\n            status_code=500,\n            detail=create_error_detail(\n                code=\"UPLOAD_FAILED\",\n                message=\"Failed to save the uploaded file.\",\n                context={\n                    \"filename\": file.filename,\n                    \"file_size_bytes\": file_size,\n                    \"error_type\": type(e).__name__,\n                    \"error_message\": str(e)\n                }\n            )\n        )\n",
        "last_modified": "2025-12-25T21:22:14.834302"
      },
      "task_intent": {
        "title": "001-complete-guidelines-rag-pdf-import",
        "description": "",
        "from_plan": false
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2025-12-25T01:36:12.606283",
  "last_updated": "2025-12-25T01:36:12.619100"
}