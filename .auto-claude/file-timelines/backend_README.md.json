{
  "file_path": "backend/README.md",
  "main_branch_history": [],
  "task_views": {
    "001-complete-guidelines-rag-pdf-import": {
      "task_id": "001-complete-guidelines-rag-pdf-import",
      "branch_point": {
        "commit_hash": "d092d181e511c0ef7a36dcfd2dfe3f083cbae73e",
        "content": "",
        "timestamp": "2025-12-25T01:35:52.079046"
      },
      "worktree_state": {
        "content": "# Czech MedAI Backend\n\nPython backend powering the Czech MedAI Assistant. Handles AI orchestration, data processing, and integration with S\u00daKL.\n\n## \ud83d\udee0\ufe0f Setup\n\n**Important**: Run all commands from the **project root folder** (`v0-benjamin`) to ensure correct module resolution.\n\n1.  **Create Virtual Environment**:\n    ```bash\n    python -m venv backend/venv\n    source backend/venv/bin/activate  # macOS/Linux\n    # .\\backend\\venv\\Scripts\\activate  # Windows\n    ```\n\n2.  **Install Dependencies**:\n    ```bash\n    pip install -r backend/requirements.txt\n    ```\n\n3.  **Environment Variables**:\n    Create `.env` file in the `backend` directory (copy from `backend/.env.example`).\n    Required variables:\n    - `OPENAI_API_KEY`: Required for generating S\u00daKL embeddings (S\u00e9mantick\u00e9 vyhled\u00e1v\u00e1n\u00ed)\n    - `ANTHROPIC_API_KEY`: For Claude 3 (Required)\n    - `GOOGLE_API_KEY`: For Audio Transcription (Required)\n    - `SUPABASE_URL`: Database URL\n    - `SUPABASE_KEY`: Service Role Key (Required for pipeline writes)\n\n## \ud83d\ude80 Running the API\n\nStart the FastAPI server (from the **project root** directory):\n\n```bash\nuvicorn backend.main:app --reload --port 8000\n```\n\n- **API URL**: `http://localhost:8000`\n- **Documentation**: `http://localhost:8000/docs`\n\n## \ud83d\udd10 Authentication\n\nAll API endpoints (except `/docs`, `/health`) require a valid Bearer Token from Supabase Auth.\n\n```http\nAuthorization: Bearer <your_jwt_token>\n```\n\n## \ud83d\udd0c API Endpoints\n\n### 1. Chat & Query (`/api/v1/query`)\n\n#### `POST /api/v1/query`\nStandard chat endpoint (non-streaming).\n\n**Body:**\n```json\n{\n  \"message\": \"Jak\u00e9 je d\u00e1vkov\u00e1n\u00ed aspirinu?\",\n  \"history\": [],\n  \"session_id\": \"optional-uuid\"\n}\n```\n\n#### `POST /api/v1/query/stream`\nStreaming chat endpoint (NDJSON). Returns chunks of tokens and metadata.\n\n### 2. Drugs (`/api/v1/drugs`)\n\n#### `GET /api/v1/drugs/search`\nSemantic and full-text search for drugs.\n\n**Parameters:**\n- `q`: Search query (e.g., \"aspirine\", \"l\u00e9k na bolest hlavy\")\n- `limit`: Max results (default 20)\n\n**Response:**\n```json\n[\n  {\n    \"sukl_code\": \"0046214\",\n    \"name\": \"ASPIRIN C\",\n    \"atc_name\": \"KYSELINA ACETYLSALICYLOV\u00c1...\",\n    \"price\": 120.50,\n    \"similarity\": 0.85\n  }\n]\n```\n\n#### `GET /api/v1/drugs/{sukl_code}`\nGet detailed information about a specific drug.\n\n### 3. AI Tools (`/api/v1/ai`)\n\n#### `POST /api/v1/ai/epicrisis`\nGenerate medical report from notes.\n\n#### `POST /api/v1/ai/translate`\nTranslate medical text (default target: Czech).\n\n#### `POST /api/v1/ai/transcribe`\nTranscribe audio file (e.g., patient visit recording).\n\n\n## \ud83d\udc89 S\u00daKL Data Pipeline\n\nThe project includes a robust ETL pipeline for processing data from S\u00daKL (St\u00e1tn\u00ed \u00fastav pro kontrolu l\u00e9\u010div).\nIt handles:\n1. **DLP (L\u00e9\u010diva)**: Monthly & eRecept updates.\n2. **Pricing (Ceny)**: Current prices & Historical archives (LEK-13).\n3. **Documents**: SPC/PIL links.\n4. **Vectors**: Semantic embeddings for search.\n\n**Important**: Run the pipeline from the **project root folder** (one level up from `backend`) to ensure correct module resolution.\n\n```bash\n# From v0-benjamin root\npython -m backend.pipeline.run_pipeline [flags]\n```\n\n### Available Commands\n\n- **Full Pipeline** (Download, Parse, Import, Embed):\n  ```bash\n  python -m backend.pipeline.run_pipeline --drugs --pricing --documents --with-embeddings\n  ```\n\n- **Individual Steps**:\n  ```bash\n  # 1. Download raw CSVs from S\u00daKL\n  python -m backend.pipeline.run_pipeline --download\n\n  # 2. Process Drugs (DLP) + Embeddings\n  python -m backend.pipeline.run_pipeline --drugs --with-embeddings\n\n  # 3. Process Pricing (Current & History)\n  python -m backend.pipeline.run_pipeline --pricing\n\n  # 4. Process SPC/PIL Documents\n  python -m backend.pipeline.run_pipeline --documents\n  ```\n\n- **Options**:\n  - `--limit <number>`: Process only N items (useful for testing)\n  - `--with-embeddings`: Generate OpenAI vectors for drugs (Costs money!)\n  - `--dry-run`: Run without writing to database\n\n## \ud83e\uddea Testing\n\nRun tests using `pytest`:\n\n```bash\n# From backend directory\npytest\n```\n",
        "last_modified": "2025-12-25T21:22:14.806930"
      },
      "task_intent": {
        "title": "001-complete-guidelines-rag-pdf-import",
        "description": "",
        "from_plan": false
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2025-12-25T01:36:12.378812",
  "last_updated": "2025-12-25T01:36:12.391780"
}