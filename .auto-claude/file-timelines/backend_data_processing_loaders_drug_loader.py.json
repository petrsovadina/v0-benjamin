{
  "file_path": "backend/data_processing/loaders/drug_loader.py",
  "main_branch_history": [],
  "task_views": {
    "001-complete-guidelines-rag-pdf-import": {
      "task_id": "001-complete-guidelines-rag-pdf-import",
      "branch_point": {
        "commit_hash": "d092d181e511c0ef7a36dcfd2dfe3f083cbae73e",
        "content": "",
        "timestamp": "2025-12-25T01:35:52.079046"
      },
      "worktree_state": {
        "content": "from typing import List, Dict, Any\nimport logging\nfrom backend.data_processing.utils.supabase_client import SupabaseSingleton\n\nlogger = logging.getLogger(__name__)\n\nclass DrugLoader:\n    \"\"\"\n    Loads drug data into Supabase 'drugs' table.\n    \"\"\"\n    def __init__(self):\n        self.supabase = SupabaseSingleton.get_client()\n\n    def load_drugs(self, drugs: List[Dict[str, Any]], batch_size: int = 100):\n        \"\"\"\n        Upserts drugs in batches.\n        \"\"\"\n        total = len(drugs)\n        logger.info(f\"Starting upload of {total} drugs to Supabase...\")\n        \n        for i in range(0, total, batch_size):\n            batch = drugs[i : i + batch_size]\n            try:\n                # Upsert based on 'sukl_code'. \n                data = self.supabase.table(\"drugs\").upsert(\n                    batch, \n                    on_conflict=\"sukl_code\"\n                ).execute()\n                logger.info(f\"Uploaded batch {i//batch_size + 1}/{(total//batch_size) + 1}\")\n            except Exception as e:\n                logger.error(f\"Error uploading batch starting at index {i}: {e}\")\n                import traceback\n                traceback.print_exc()\n                \n        logger.info(\"Upload complete.\")\n",
        "last_modified": "2025-12-25T21:22:14.905565"
      },
      "task_intent": {
        "title": "001-complete-guidelines-rag-pdf-import",
        "description": "",
        "from_plan": false
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2025-12-25T01:36:13.252126",
  "last_updated": "2025-12-25T01:36:13.265074"
}