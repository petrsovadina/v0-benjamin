{
  "file_path": "backend/data_processing/parsers/sukl_pricing_parser.py",
  "main_branch_history": [],
  "task_views": {
    "001-complete-guidelines-rag-pdf-import": {
      "task_id": "001-complete-guidelines-rag-pdf-import",
      "branch_point": {
        "commit_hash": "d092d181e511c0ef7a36dcfd2dfe3f083cbae73e",
        "content": "",
        "timestamp": "2025-12-25T01:35:52.079046"
      },
      "worktree_state": {
        "content": "import csv\nimport logging\nfrom pathlib import Path\nfrom typing import List, Dict, Any\n\nlogger = logging.getLogger(__name__)\n\nclass SuklPricingParser:\n    \"\"\"\n    Parses S\u00daKL Pricing CSV files (SCAU - Seznam cen a \u00fahrad).\n    \"\"\"\n\n    def parse_pricing(self, file_path: Path) -> List[Dict[str, Any]]:\n        results = []\n        try:\n            import zipfile\n            \n            # Check if zip\n            if file_path.suffix.lower() == '.zip':\n                logger.info(f\"Detected ZIP archive: {file_path}\")\n                with zipfile.ZipFile(file_path, 'r') as z:\n                    for filename in z.namelist():\n                        if filename.lower().endswith('.csv') or filename.lower().endswith('.txt'):\n                            logger.info(f\"Processing archived file: {filename}\")\n                            with z.open(filename) as f:\n                                # ZipFile opens in bytes mode, need to decode\n                                # LEK-13 is typically cp1250\n                                content = f.read().decode('cp1250', errors='replace').splitlines()\n                                results.extend(self._parse_csv_content(content, filename))\n            else:\n                # Normal CSV file\n                with open(file_path, mode='r', encoding='cp1250', errors='replace') as f:\n                    content = f.readlines()\n                    results.extend(self._parse_csv_content(content, file_path.name))\n                        \n        except Exception as e:\n            logger.error(f\"Failed to parse Pricing file {file_path}: {e}\")\n            raise\n            \n        return results\n\n    def _parse_csv_content(self, lines: List[str], source_name: str) -> List[Dict[str, Any]]:\n        results = []\n        try:\n             # Basic heuristic for delimiter\n            if not lines:\n                return []\n                \n            first_line = lines[0]\n            delimiter = ';' if ';' in first_line else ','\n            \n            reader = csv.DictReader(lines, delimiter=delimiter)\n            \n            for row in reader:\n                clean_row = {k.strip(): v.strip() for k, v in row.items() if k}\n                \n                try:\n                    # Helper to find key case-insensitive and safe\n                    def get_val(candidates: List[str], default=\"\"):\n                        for c in candidates:\n                            for k in clean_row.keys():\n                                if c.lower() in k.lower():\n                                    return clean_row[k]\n                        return default\n\n                    # LEK-13 column mapping\n                    # Try explicit then fuzzy\n                    sukl_code = clean_row.get(\"K\u00f3d S\u00daKL\") or get_val([\"k\u00f3d s\u00fakl\", \"kod sukl\", \"k\u00f3d\"], \"\")\n                    \n                    if not sukl_code:\n                        continue\n                    \n                    # Normalize SUKL code to 7 digits\n                    sukl_code = sukl_code.zfill(7)\n                    \n                    name = get_val([\"n\u00e1zev p\u0159\u00edpravku\", \"nazev pripravku\", \"n\u00e1zev\", \"nazev\"], \"\")\n\n                    # Parse numeric values\n                    def parse_num(val):\n                        if not val: return None\n                        try:\n                            return float(val.replace(',', '.').replace(' ', ''))\n                        except ValueError:\n                            return 0.0\n                    \n                    price = parse_num(clean_row.get(\"N\u00e1kupn\u00ed cena bez DPH\") or get_val([\"n\u00e1kupn\u00ed cena\", \"nakupni cena\"], \"0\"))\n                    copay = parse_num(get_val([\"kone\u010dn\u00e1\", \"konecna\", \"doplatek\"], \"0\")) \n                    dispensed_count = int(parse_num(get_val([\"po\u010det balen\u00ed\", \"pocet baleni\"], \"0\")) or 0)\n                    \n                    is_reimbursed = get_val([\"hrazeno\"], \"Ne\").lower() == \"ano\"\n                    \n                    # Parse date from 'Obdob\u00ed' (e.g. 2024.01 or 202401)\n                    raw_date = clean_row.get(\"Obdob\u00ed\") or get_val([\"obdob\u00ed\", \"obdobi\"], None)\n                    valid_from = None\n                    if raw_date:\n                        try:\n                            # Usually YYYY.MM or YYYYMM\n                            clean_date = raw_date.replace('.', '')\n                            if len(clean_date) == 6:\n                                valid_from = f\"{clean_date[:4]}-{clean_date[4:]}-01\"\n                        except:\n                            pass\n\n                    item = {\n                        \"sukl_code\": sukl_code,\n                        \"name\": name,\n                        \"max_price_manufacturer\": price,\n                        \"reimbursement_amount\": 0.0, \n                        \"max_copayment\": copay, \n                        \"dispensed_count\": dispensed_count,\n                        \"coverage_type\": \"Hrazeno\" if is_reimbursed else \"Nehrazeno\",\n                        \"is_reimbursed\": is_reimbursed,\n                        \"valid_from\": valid_from,\n                        \"source_file\": source_name\n                    }\n                    results.append(item)\n                except Exception as row_e:\n                    continue\n        except Exception as e:\n             logger.error(f\"Error parsing content from {source_name}: {e}\")\n             \n        return results\n",
        "last_modified": "2025-12-25T21:22:14.926721"
      },
      "task_intent": {
        "title": "001-complete-guidelines-rag-pdf-import",
        "description": "",
        "from_plan": false
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2025-12-25T01:36:13.480578",
  "last_updated": "2025-12-25T01:36:13.493538"
}