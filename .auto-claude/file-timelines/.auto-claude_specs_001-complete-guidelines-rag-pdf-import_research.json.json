{
  "file_path": ".auto-claude/specs/001-complete-guidelines-rag-pdf-import/research.json",
  "main_branch_history": [],
  "task_views": {
    "001-complete-guidelines-rag-pdf-import": {
      "task_id": "001-complete-guidelines-rag-pdf-import",
      "branch_point": {
        "commit_hash": "d092d181e511c0ef7a36dcfd2dfe3f083cbae73e",
        "content": "",
        "timestamp": "2025-12-25T01:35:52.079046"
      },
      "worktree_state": {
        "content": "{\n  \"integrations_researched\": [\n    {\n      \"name\": \"LangChain Community\",\n      \"type\": \"library\",\n      \"verified_package\": {\n        \"name\": \"langchain-community\",\n        \"install_command\": \"pip install langchain-community\",\n        \"version\": \">=0.0.10\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"from langchain_community.document_loaders import PyPDFLoader\"\n        ],\n        \"initialization\": \"loader = PyPDFLoader(file_path)\\ndocs = loader.load()\",\n        \"key_functions\": [\n          \"PyPDFLoader(file_path).load() - Returns list of Document objects, one per page\",\n          \"Document.page_content - The text content\",\n          \"Document.metadata - Contains source path and page number\"\n        ],\n        \"verified_against\": \"Context7 MCP: /websites/langchain_oss_python_langchain\"\n      },\n      \"configuration\": {\n        \"env_vars\": [],\n        \"dependencies\": [\"pypdf\"]\n      },\n      \"gotchas\": [\n        \"PyPDFLoader creates one Document object per page\",\n        \"Page numbers start at 0 in metadata\",\n        \"Metadata structure: {'source': 'filepath', 'page': 0}\"\n      ],\n      \"research_sources\": [\n        \"Context7 MCP: /websites/langchain_oss_python_langchain\",\n        \"https://docs.langchain.com/oss/python/langchain/knowledge-base\"\n      ]\n    },\n    {\n      \"name\": \"LangChain Text Splitters\",\n      \"type\": \"library\",\n      \"verified_package\": {\n        \"name\": \"langchain-text-splitters\",\n        \"install_command\": \"pip install langchain-text-splitters\",\n        \"version\": \"latest\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"from langchain_text_splitters import RecursiveCharacterTextSplitter\"\n        ],\n        \"initialization\": \"text_splitter = RecursiveCharacterTextSplitter(\\n    chunk_size=1000,\\n    chunk_overlap=200,\\n    separators=[\\\"\\\\n\\\\n\\\", \\\"\\\\n\\\", \\\" \\\", \\\"\\\"],\\n    add_start_index=True\\n)\",\n        \"key_functions\": [\n          \"split_documents(docs) - Splits Document objects into smaller chunks\",\n          \"split_text(text) - Splits raw text strings\"\n        ],\n        \"verified_against\": \"Context7 MCP: /websites/langchain_oss_python_langchain\"\n      },\n      \"configuration\": {\n        \"recommended_settings\": {\n          \"chunk_size\": \"1000 characters (for medical documents, consider preserving context)\",\n          \"chunk_overlap\": \"200 characters (20% overlap recommended)\",\n          \"separators\": \"[\\\"\\\\n\\\\n\\\", \\\"\\\\n\\\", \\\" \\\", \\\"\\\"] - Hierarchical splitting\",\n          \"add_start_index\": \"true - Tracks position in original document\"\n        }\n      },\n      \"gotchas\": [\n        \"RecursiveCharacterTextSplitter tries separators in order - starts with paragraphs, then sentences\",\n        \"Chunk overlap ensures context preservation across boundaries\",\n        \"add_start_index=True adds 'start_index' to metadata for tracking position\",\n        \"Chunk size is character-based, not token-based\",\n        \"Medical documents may need larger chunks to preserve clinical context\"\n      ],\n      \"research_sources\": [\n        \"Context7 MCP: /websites/langchain_oss_python_langchain\",\n        \"Code example from existing codebase: backend/data_processing/loaders/guidelines_loader.py\"\n      ]\n    },\n    {\n      \"name\": \"LangChain OpenAI\",\n      \"type\": \"library\",\n      \"verified_package\": {\n        \"name\": \"langchain-openai\",\n        \"install_command\": \"pip install langchain-openai\",\n        \"version\": \">=0.0.5\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"from langchain_openai import OpenAIEmbeddings\"\n        ],\n        \"initialization\": \"embeddings = OpenAIEmbeddings(\\n    model=\\\"text-embedding-3-small\\\",\\n    api_key=settings.OPENAI_API_KEY\\n)\",\n        \"key_functions\": [\n          \"embed_documents(texts) - Generate embeddings for list of texts\",\n          \"embed_query(text) - Generate embedding for single query text\"\n        ],\n        \"verified_against\": \"Context7 MCP + existing codebase\"\n      },\n      \"configuration\": {\n        \"env_vars\": [\"OPENAI_API_KEY\"],\n        \"model_options\": {\n          \"text-embedding-3-small\": \"1536 dimensions, cost-effective, good performance\",\n          \"text-embedding-3-large\": \"3072 dimensions (customizable), higher quality\",\n          \"text-embedding-ada-002\": \"1536 dimensions, legacy model\"\n        }\n      },\n      \"gotchas\": [\n        \"text-embedding-3-small is recommended for cost vs performance\",\n        \"Batch embeddings are more efficient than individual calls\",\n        \"API rate limits apply - handle with batching\",\n        \"Existing code uses text-embedding-3-small model\"\n      ],\n      \"research_sources\": [\n        \"Context7 MCP: /openai/openai-python\",\n        \"Existing implementation: backend/data_processing/loaders/guidelines_loader.py\"\n      ]\n    },\n    {\n      \"name\": \"pdfplumber\",\n      \"type\": \"library\",\n      \"verified_package\": {\n        \"name\": \"pdfplumber\",\n        \"install_command\": \"pip install pdfplumber\",\n        \"version\": \">=0.10.3\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"import pdfplumber\"\n        ],\n        \"initialization\": \"with pdfplumber.open(pdf_path) as pdf:\\n    page = pdf.pages[0]\",\n        \"key_functions\": [\n          \"page.extract_text() - Simple text extraction\",\n          \"page.extract_text(layout=True) - Layout-preserving extraction\",\n          \"page.extract_words() - Extract words with bounding boxes\",\n          \"page.extract_tables() - Extract tabular data\",\n          \"page.within_bbox((x0, top, x1, bottom)) - Extract from specific region\"\n        ],\n        \"verified_against\": \"Context7 MCP: /jsvine/pdfplumber\"\n      },\n      \"configuration\": {\n        \"extraction_options\": {\n          \"x_tolerance\": \"Horizontal space tolerance (default: 3)\",\n          \"y_tolerance\": \"Vertical space tolerance (default: 3)\",\n          \"layout\": \"Preserve layout (default: False)\",\n          \"layout_mode_space_vertically\": \"Include vertical whitespace (default: True)\"\n        }\n      },\n      \"gotchas\": [\n        \"Better for complex PDFs with tables and layout preservation than pypdf\",\n        \"extract_text(layout=True) preserves spatial layout but may include extra whitespace\",\n        \"Can handle scanned PDFs if text layer exists (no OCR built-in)\",\n        \"Good for medical guidelines with structured tables\",\n        \"Page indexing starts at 0\",\n        \"Use within_bbox() to extract specific regions like headers/footers\"\n      ],\n      \"research_sources\": [\n        \"Context7 MCP: /jsvine/pdfplumber\",\n        \"https://github.com/jsvine/pdfplumber\"\n      ]\n    },\n    {\n      \"name\": \"pypdf\",\n      \"type\": \"library\",\n      \"verified_package\": {\n        \"name\": \"pypdf\",\n        \"install_command\": \"pip install pypdf\",\n        \"version\": \">=3.17.4\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"from pypdf import PdfReader\"\n        ],\n        \"initialization\": \"reader = PdfReader(pdf_path)\\npage = reader.pages[0]\",\n        \"key_functions\": [\n          \"page.extract_text() - Basic text extraction\",\n          \"page.extract_text(orientations=0) - Extract specific orientation\",\n          \"page.extract_text(extraction_mode='layout') - Layout-preserving mode\"\n        ],\n        \"verified_against\": \"Context7 MCP: /py-pdf/pypdf\"\n      },\n      \"configuration\": {\n        \"extraction_modes\": {\n          \"plain\": \"Simple text extraction (default)\",\n          \"layout\": \"Preserve spatial layout\"\n        }\n      },\n      \"gotchas\": [\n        \"Used by LangChain's PyPDFLoader internally\",\n        \"Simpler and faster than pdfplumber for basic text extraction\",\n        \"May not handle complex layouts as well as pdfplumber\",\n        \"Good for straightforward PDF documents\",\n        \"Less feature-rich than pdfplumber for table extraction\"\n      ],\n      \"research_sources\": [\n        \"Context7 MCP: /py-pdf/pypdf\",\n        \"https://github.com/py-pdf/pypdf\"\n      ]\n    },\n    {\n      \"name\": \"FastAPI\",\n      \"type\": \"library\",\n      \"verified_package\": {\n        \"name\": \"fastapi\",\n        \"install_command\": \"pip install fastapi\",\n        \"version\": \">=0.110.0\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"from fastapi import FastAPI, File, UploadFile, BackgroundTasks\",\n          \"from typing import Annotated\"\n        ],\n        \"initialization\": \"app = FastAPI()\",\n        \"key_functions\": [\n          \"@app.post('/upload') with file: UploadFile = File(...)\",\n          \"await file.read() - Read file content\",\n          \"file.filename, file.content_type - File metadata\",\n          \"background_tasks.add_task(func) - Background processing\"\n        ],\n        \"verified_against\": \"Context7 MCP: /fastapi/fastapi\"\n      },\n      \"configuration\": {\n        \"file_upload_patterns\": {\n          \"single_file\": \"file: UploadFile = File(...)\",\n          \"multiple_files\": \"files: list[UploadFile] = File(...)\",\n          \"with_form_data\": \"file: UploadFile = File(...), description: str = Form()\"\n        }\n      },\n      \"gotchas\": [\n        \"UploadFile is better for large files (streaming) vs bytes (in-memory)\",\n        \"Use BackgroundTasks for long-running operations like PDF processing\",\n        \"File validation should check .filename.endswith('.pdf')\",\n        \"Content is async - use await file.read()\",\n        \"Save file before adding to background tasks (file stream may close)\",\n        \"Existing endpoint at /upload/guideline already implements this pattern\"\n      ],\n      \"research_sources\": [\n        \"Context7 MCP: /fastapi/fastapi\",\n        \"Existing implementation: backend/app/api/v1/endpoints/admin.py\"\n      ]\n    },\n    {\n      \"name\": \"Supabase Python\",\n      \"type\": \"library\",\n      \"verified_package\": {\n        \"name\": \"supabase\",\n        \"install_command\": \"pip install supabase\",\n        \"version\": \">=2.3.0\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"from supabase import create_client, Client\"\n        ],\n        \"initialization\": \"supabase: Client = create_client(url, key)\",\n        \"key_functions\": [\n          \"supabase.table('table_name').insert(data).execute()\",\n          \"supabase.table('table_name').select('*').execute()\",\n          \"supabase.table('table_name').delete().filter('column', 'eq', value).execute()\",\n          \"supabase.table('table_name').upsert(data).execute()\"\n        ],\n        \"verified_against\": \"Context7 MCP: /supabase/supabase-py\"\n      },\n      \"configuration\": {\n        \"env_vars\": [\n          \"SUPABASE_URL\",\n          \"SUPABASE_KEY\"\n        ],\n        \"vector_storage\": {\n          \"table_structure\": \"guidelines table with (id, title, organization, publication_year, is_czech, content, metadata, embedding)\",\n          \"embedding_column\": \"vector type for pgvector similarity search\",\n          \"metadata_format\": \"JSONB column storing {source, page, ...}\"\n        }\n      },\n      \"gotchas\": [\n        \"Delete existing chunks before re-inserting to avoid duplicates\",\n        \"Use .filter('metadata->>source', 'eq', filename) for JSONB queries\",\n        \"Batch inserts (50-100 records) are more efficient than single inserts\",\n        \"Vector embeddings must match the dimension configured in pgvector\",\n        \"Existing implementation uses idempotent pattern: delete then insert\",\n        \"The guidelines table schema is defined in 008_guidelines.sql migration\"\n      ],\n      \"research_sources\": [\n        \"Context7 MCP: /supabase/supabase-py\",\n        \"Existing implementation: backend/data_processing/loaders/guidelines_loader.py\",\n        \"Existing database client: backend/app/core/database.py\"\n      ]\n    },\n    {\n      \"name\": \"OpenAI Python SDK\",\n      \"type\": \"library\",\n      \"verified_package\": {\n        \"name\": \"openai\",\n        \"install_command\": \"pip install openai\",\n        \"version\": \">=1.12.0\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"from openai import OpenAI\"\n        ],\n        \"initialization\": \"client = OpenAI(api_key=api_key)\",\n        \"key_functions\": [\n          \"client.embeddings.create(model='text-embedding-3-small', input=texts)\",\n          \"response.data[i].embedding - Access embedding vectors\"\n        ],\n        \"verified_against\": \"Context7 MCP: /openai/openai-python\"\n      },\n      \"configuration\": {\n        \"env_vars\": [\"OPENAI_API_KEY\"],\n        \"models\": {\n          \"text-embedding-3-small\": {\n            \"dimensions\": 1536,\n            \"use_case\": \"Cost-effective, good for most applications\",\n            \"cost\": \"Lower cost per token\"\n          },\n          \"text-embedding-3-large\": {\n            \"dimensions\": \"3072 (customizable with dimensions parameter)\",\n            \"use_case\": \"Higher quality embeddings\",\n            \"cost\": \"Higher cost per token\"\n          }\n        }\n      },\n      \"gotchas\": [\n        \"Batch multiple texts in single API call for efficiency\",\n        \"API rate limits apply - implement retry logic\",\n        \"Embeddings are normalized (unit length)\",\n        \"Dimensions must match vector database schema\",\n        \"LangChain wraps this - prefer LangChain's OpenAIEmbeddings for integration\"\n      ],\n      \"research_sources\": [\n        \"Context7 MCP: /openai/openai-python\",\n        \"Existing implementation: backend/data_processing/embeddings/embedding_generator.py\"\n      ]\n    },\n    {\n      \"name\": \"pytesseract\",\n      \"type\": \"library\",\n      \"verified_package\": {\n        \"name\": \"pytesseract\",\n        \"install_command\": \"pip install pytesseract\",\n        \"version\": \">=0.3.10\",\n        \"verified\": true\n      },\n      \"api_patterns\": {\n        \"imports\": [\n          \"import pytesseract\"\n        ],\n        \"initialization\": \"N/A - Direct function calls\",\n        \"key_functions\": [\n          \"pytesseract.image_to_string(image) - OCR on images\"\n        ],\n        \"verified_against\": \"PyPI package listing\"\n      },\n      \"configuration\": {\n        \"dependencies\": [\"Tesseract OCR system binary must be installed separately\"],\n        \"env_vars\": [\"TESSERACT_CMD (optional path to tesseract binary)\"]\n      },\n      \"gotchas\": [\n        \"Requires external Tesseract OCR installation (not Python-only)\",\n        \"Needed only for scanned PDFs without text layer\",\n        \"May not be needed if medical guidelines are born-digital PDFs\",\n        \"Performance overhead for OCR processing\",\n        \"Listed in requirements.txt but may be optional for this task\"\n      ],\n      \"research_sources\": [\n        \"Existing requirement: backend/requirements.txt\",\n        \"PyPI: https://pypi.org/project/pytesseract/\"\n      ]\n    }\n  ],\n  \"unverified_claims\": [],\n  \"recommendations\": [\n    \"Use LangChain's PyPDFLoader as primary PDF loader - it's already integrated and handles one-doc-per-page\",\n    \"RecursiveCharacterTextSplitter with chunk_size=1000, overlap=200 is good starting point - may need tuning for medical context\",\n    \"Consider larger chunks (1500-2000) for medical guidelines to preserve clinical context and citations\",\n    \"pdfplumber is available but not needed unless complex table extraction is required\",\n    \"Existing GuidelinesLoader implementation is solid foundation - already handles batching, metadata, and idempotent uploads\",\n    \"text-embedding-3-small is cost-effective and sufficient for Czech medical text\",\n    \"Batch embeddings in groups of 50-100 to optimize API usage and avoid rate limits\",\n    \"Ensure metadata preserves both document name AND page number for proper citations\",\n    \"Test with actual Czech medical guideline PDFs to validate format compatibility\",\n    \"Background task processing is already implemented - good for handling large PDFs\",\n    \"Consider adding progress tracking/logging for multi-page PDF processing\",\n    \"Validate that pgvector index exists on embeddings column for fast similarity search\"\n  ],\n  \"multi_format_support_strategy\": {\n    \"approach\": \"Test-and-adapt pattern\",\n    \"rationale\": \"Medical guidelines may come in various PDF formats (scanned, digital, mixed)\",\n    \"detection_logic\": [\n      \"Try PyPDFLoader first (handles most born-digital PDFs)\",\n      \"If text extraction is empty or minimal, try pdfplumber with layout=True\",\n      \"If still empty, may be scanned PDF - would need OCR (pytesseract)\",\n      \"Log extraction method used for monitoring\"\n    ],\n    \"formats_to_test\": [\n      \"Born-digital PDF with standard text layer\",\n      \"PDF with complex tables/layout\",\n      \"Scanned PDF (if OCR is needed)\"\n    ]\n  },\n  \"context7_libraries_used\": [\n    \"/websites/langchain_oss_python_langchain\",\n    \"/jsvine/pdfplumber\",\n    \"/py-pdf/pypdf\",\n    \"/fastapi/fastapi\",\n    \"/supabase/supabase-py\",\n    \"/openai/openai-python\"\n  ],\n  \"created_at\": \"2024-12-24T10:30:00Z\"\n}\n",
        "last_modified": "2025-12-25T21:22:14.783377"
      },
      "task_intent": {
        "title": "001-complete-guidelines-rag-pdf-import",
        "description": "",
        "from_plan": false
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2025-12-25T01:36:12.237425",
  "last_updated": "2025-12-25T01:36:12.250333"
}