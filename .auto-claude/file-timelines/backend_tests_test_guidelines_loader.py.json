{
  "file_path": "backend/tests/test_guidelines_loader.py",
  "main_branch_history": [],
  "task_views": {
    "001-complete-guidelines-rag-pdf-import": {
      "task_id": "001-complete-guidelines-rag-pdf-import",
      "branch_point": {
        "commit_hash": "d092d181e511c0ef7a36dcfd2dfe3f083cbae73e",
        "content": "",
        "timestamp": "2025-12-25T01:35:52.079046"
      },
      "worktree_state": {
        "content": "import pytest\nimport sys\nfrom unittest.mock import MagicMock, patch\n\n# Mock all external dependencies before importing the module\nmock_langchain_docs = MagicMock()\nmock_langchain_splitter = MagicMock()\nmock_langchain_openai = MagicMock()\nmock_supabase_module = MagicMock()\nmock_settings = MagicMock()\nmock_database = MagicMock()\nmock_logger = MagicMock()\n\n# Pre-configure mocks\nmock_settings.OPENAI_API_KEY = \"test-api-key\"\n\n\n@pytest.fixture\ndef mock_modules():\n    \"\"\"Setup sys.modules mocks for all dependencies.\"\"\"\n    original_modules = {}\n    modules_to_mock = {\n        'langchain_community': MagicMock(),\n        'langchain_community.document_loaders': mock_langchain_docs,\n        'langchain_text_splitters': mock_langchain_splitter,\n        'langchain_openai': mock_langchain_openai,\n        'supabase': mock_supabase_module,\n        'backend': MagicMock(),\n        'backend.app': MagicMock(),\n        'backend.app.core': MagicMock(),\n        'backend.app.core.config': MagicMock(settings=mock_settings),\n        'backend.app.core.database': mock_database,\n        'backend.services': MagicMock(),\n        'backend.services.logger': mock_logger,\n    }\n\n    for name, mock in modules_to_mock.items():\n        if name in sys.modules:\n            original_modules[name] = sys.modules[name]\n        sys.modules[name] = mock\n\n    # Setup specific attributes\n    sys.modules['backend.app.core.config'].settings = mock_settings\n    sys.modules['backend.app.core.database'].get_supabase_client = MagicMock()\n    sys.modules['backend.services.logger'].get_logger = MagicMock(return_value=MagicMock())\n\n    yield modules_to_mock\n\n    # Cleanup\n    for name in modules_to_mock:\n        if name in original_modules:\n            sys.modules[name] = original_modules[name]\n        elif name in sys.modules:\n            del sys.modules[name]\n\n\nclass TestGuidelinesLoaderClass:\n    \"\"\"Tests for GuidelinesLoader class without full module import.\"\"\"\n\n    def test_embed_with_retry_success_first_attempt(self):\n        \"\"\"Test successful embedding on first attempt.\"\"\"\n        # Create mock embeddings\n        mock_embeddings = MagicMock()\n        mock_embeddings.embed_documents.return_value = [[0.1] * 1536, [0.2] * 1536]\n\n        # Create a simple GuidelinesLoader-like object to test retry logic\n        class TestRetryLogic:\n            def __init__(self):\n                self.embeddings = mock_embeddings\n\n            def _embed_with_retry(self, texts, batch_index, filename):\n                max_retries = 3\n                base_delay = 1.0\n                max_delay = 10.0\n                last_exception = None\n\n                for attempt in range(1, max_retries + 1):\n                    try:\n                        vectors = self.embeddings.embed_documents(texts)\n                        return vectors\n                    except Exception as e:\n                        last_exception = e\n                        if attempt < max_retries:\n                            import time\n                            delay = min(base_delay * (2 ** (attempt - 1)), max_delay)\n                            time.sleep(delay)\n\n                raise last_exception\n\n        loader = TestRetryLogic()\n        texts = [\"text1\", \"text2\"]\n        result = loader._embed_with_retry(texts, batch_index=0, filename=\"test.pdf\")\n\n        assert len(result) == 2\n        assert result[0] == [0.1] * 1536\n        mock_embeddings.embed_documents.assert_called_once_with(texts)\n\n    def test_embed_with_retry_success_after_retry(self):\n        \"\"\"Test successful embedding after a retry.\"\"\"\n        mock_embeddings = MagicMock()\n        mock_embeddings.embed_documents.side_effect = [\n            Exception(\"Rate limit\"),\n            [[0.3] * 1536]\n        ]\n\n        class TestRetryLogic:\n            def __init__(self):\n                self.embeddings = mock_embeddings\n\n            def _embed_with_retry(self, texts, batch_index, filename):\n                max_retries = 3\n                base_delay = 1.0\n                max_delay = 10.0\n                last_exception = None\n\n                for attempt in range(1, max_retries + 1):\n                    try:\n                        vectors = self.embeddings.embed_documents(texts)\n                        return vectors\n                    except Exception as e:\n                        last_exception = e\n                        if attempt < max_retries:\n                            import time\n                            delay = min(base_delay * (2 ** (attempt - 1)), max_delay)\n                            time.sleep(delay)\n\n                raise last_exception\n\n        with patch('time.sleep'):\n            loader = TestRetryLogic()\n            result = loader._embed_with_retry([\"text1\"], batch_index=0, filename=\"test.pdf\")\n\n        assert result == [[0.3] * 1536]\n        assert mock_embeddings.embed_documents.call_count == 2\n\n    def test_embed_with_retry_exhausted(self):\n        \"\"\"Test exception raised when all retries are exhausted.\"\"\"\n        mock_embeddings = MagicMock()\n        mock_embeddings.embed_documents.side_effect = Exception(\"Persistent error\")\n\n        class TestRetryLogic:\n            def __init__(self):\n                self.embeddings = mock_embeddings\n\n            def _embed_with_retry(self, texts, batch_index, filename):\n                max_retries = 3\n                base_delay = 1.0\n                max_delay = 10.0\n                last_exception = None\n\n                for attempt in range(1, max_retries + 1):\n                    try:\n                        vectors = self.embeddings.embed_documents(texts)\n                        return vectors\n                    except Exception as e:\n                        last_exception = e\n                        if attempt < max_retries:\n                            import time\n                            delay = min(base_delay * (2 ** (attempt - 1)), max_delay)\n                            time.sleep(delay)\n\n                raise last_exception\n\n        with patch('time.sleep'):\n            loader = TestRetryLogic()\n            with pytest.raises(Exception) as exc_info:\n                loader._embed_with_retry([\"text1\"], batch_index=0, filename=\"test.pdf\")\n\n        assert \"Persistent error\" in str(exc_info.value)\n        assert mock_embeddings.embed_documents.call_count == 3\n\n    def test_embed_with_retry_exponential_backoff(self):\n        \"\"\"Test that exponential backoff is applied.\"\"\"\n        mock_embeddings = MagicMock()\n        mock_embeddings.embed_documents.side_effect = [\n            Exception(\"Error 1\"),\n            Exception(\"Error 2\"),\n            [[0.5] * 1536]\n        ]\n\n        class TestRetryLogic:\n            def __init__(self):\n                self.embeddings = mock_embeddings\n\n            def _embed_with_retry(self, texts, batch_index, filename):\n                import time\n                max_retries = 3\n                base_delay = 1.0\n                max_delay = 10.0\n                last_exception = None\n\n                for attempt in range(1, max_retries + 1):\n                    try:\n                        vectors = self.embeddings.embed_documents(texts)\n                        return vectors\n                    except Exception as e:\n                        last_exception = e\n                        if attempt < max_retries:\n                            delay = min(base_delay * (2 ** (attempt - 1)), max_delay)\n                            time.sleep(delay)\n\n                raise last_exception\n\n        with patch('time.sleep') as mock_sleep:\n            loader = TestRetryLogic()\n            result = loader._embed_with_retry([\"text1\"], batch_index=0, filename=\"test.pdf\")\n\n        assert mock_sleep.call_count == 2\n        mock_sleep.assert_any_call(1.0)\n        mock_sleep.assert_any_call(2.0)\n\n\nclass TestIngestPdfsLogic:\n    \"\"\"Tests for ingest_pdfs logic patterns.\"\"\"\n\n    def test_ingest_pdfs_no_files_found(self):\n        \"\"\"Test handling when no PDF files are found.\"\"\"\n        import glob as glob_module\n\n        with patch.object(glob_module, 'glob', return_value=[]):\n            # Simulating ingest_pdfs behavior\n            pdf_files = glob_module.glob(\"test_dir/*.pdf\")\n\n            assert pdf_files == []\n            # No processing should occur\n\n    def test_ingest_pdfs_processes_files(self):\n        \"\"\"Test that PDF files are processed correctly.\"\"\"\n        import os\n        import glob as glob_module\n\n        mock_pdf_loader = MagicMock()\n        mock_doc = MagicMock()\n        mock_doc.page_content = \"Test PDF content\"\n        mock_doc.metadata = {\"page\": 0, \"source\": \"test.pdf\"}\n        mock_pdf_loader.load.return_value = [mock_doc]\n\n        mock_text_splitter = MagicMock()\n        mock_chunk = MagicMock()\n        mock_chunk.page_content = \"Test chunk\"\n        mock_chunk.metadata = {\"page\": 0}\n        mock_text_splitter.split_documents.return_value = [mock_chunk]\n\n        mock_embeddings = MagicMock()\n        mock_embeddings.embed_documents.return_value = [[0.1] * 1536]\n\n        mock_supabase = MagicMock()\n        mock_supabase.table.return_value.delete.return_value.filter.return_value.execute.return_value = None\n        mock_supabase.table.return_value.insert.return_value.execute.return_value = None\n\n        with patch.object(glob_module, 'glob', return_value=[\"test_pdfs/guideline.pdf\"]):\n            pdf_files = glob_module.glob(\"test_pdfs/*.pdf\")\n\n            assert len(pdf_files) == 1\n\n            # Simulate processing\n            for file_path in pdf_files:\n                filename = os.path.basename(file_path)\n                assert filename == \"guideline.pdf\"\n\n                # Load PDF\n                docs = mock_pdf_loader.load()\n                assert len(docs) == 1\n\n                # Split into chunks\n                chunks = mock_text_splitter.split_documents(docs)\n                assert len(chunks) == 1\n\n                # Generate embeddings\n                batch_texts = [c.page_content for c in chunks]\n                vectors = mock_embeddings.embed_documents(batch_texts)\n                assert len(vectors) == 1\n\n                # Prepare records\n                records = []\n                for j, chunk in enumerate(chunks):\n                    records.append({\n                        \"title\": filename,\n                        \"organization\": \"Unknown\",\n                        \"publication_year\": \"2024\",\n                        \"is_czech\": True,\n                        \"content\": chunk.page_content,\n                        \"metadata\": {\n                            \"source\": filename,\n                            \"page\": chunk.metadata.get(\"page\", 0),\n                            **chunk.metadata\n                        },\n                        \"embedding\": vectors[j]\n                    })\n\n                # Verify record format\n                assert records[0][\"title\"] == \"guideline.pdf\"\n                assert records[0][\"organization\"] == \"Unknown\"\n                assert records[0][\"publication_year\"] == \"2024\"\n                assert records[0][\"is_czech\"] is True\n                assert records[0][\"content\"] == \"Test chunk\"\n                assert records[0][\"metadata\"][\"source\"] == \"guideline.pdf\"\n                assert records[0][\"metadata\"][\"page\"] == 0\n\n    def test_ingest_pdfs_error_handling(self):\n        \"\"\"Test error handling during PDF processing.\"\"\"\n        import glob as glob_module\n\n        mock_pdf_loader = MagicMock()\n        mock_pdf_loader.load.side_effect = Exception(\"Cannot read PDF\")\n\n        errors_logged = []\n\n        with patch.object(glob_module, 'glob', return_value=[\"test_pdfs/bad.pdf\"]):\n            pdf_files = glob_module.glob(\"test_pdfs/*.pdf\")\n\n            for file_path in pdf_files:\n                try:\n                    docs = mock_pdf_loader.load()\n                except Exception as e:\n                    errors_logged.append(str(e))\n\n        assert len(errors_logged) == 1\n        assert \"Cannot read PDF\" in errors_logged[0]\n\n\nclass TestBatchProcessing:\n    \"\"\"Tests for batch processing behavior.\"\"\"\n\n    def test_batch_size_calculation(self):\n        \"\"\"Test that chunks are correctly batched.\"\"\"\n        batch_size = 50\n        chunks = list(range(75))  # 75 items\n\n        batches = []\n        for i in range(0, len(chunks), batch_size):\n            batch = chunks[i:i+batch_size]\n            batches.append(batch)\n\n        assert len(batches) == 2\n        assert len(batches[0]) == 50\n        assert len(batches[1]) == 25\n\n    def test_large_pdf_batch_processing(self):\n        \"\"\"Test that large PDFs are processed in batches of 50.\"\"\"\n        mock_embeddings = MagicMock()\n\n        def mock_embed(texts):\n            return [[0.1] * 1536 for _ in texts]\n        mock_embeddings.embed_documents.side_effect = mock_embed\n\n        # Create 75 mock chunks\n        mock_chunks = []\n        for i in range(75):\n            chunk = MagicMock()\n            chunk.page_content = f\"Chunk {i}\"\n            chunk.metadata = {\"page\": i}\n            mock_chunks.append(chunk)\n\n        batch_size = 50\n        records = []\n\n        for i in range(0, len(mock_chunks), batch_size):\n            batch = mock_chunks[i:i+batch_size]\n            batch_texts = [c.page_content for c in batch]\n            vectors = mock_embeddings.embed_documents(batch_texts)\n\n            for j, chunk in enumerate(batch):\n                records.append({\n                    \"content\": chunk.page_content,\n                    \"embedding\": vectors[j]\n                })\n\n        assert mock_embeddings.embed_documents.call_count == 2\n\n        # First batch should have 50 texts\n        first_call_args = mock_embeddings.embed_documents.call_args_list[0][0][0]\n        assert len(first_call_args) == 50\n\n        # Second batch should have 25 texts\n        second_call_args = mock_embeddings.embed_documents.call_args_list[1][0][0]\n        assert len(second_call_args) == 25\n\n        # Total records should be 75\n        assert len(records) == 75\n\n\nclass TestRecordFormat:\n    \"\"\"Tests for database record format.\"\"\"\n\n    def test_record_has_required_fields(self):\n        \"\"\"Test that records have all required fields per 008_guidelines.sql.\"\"\"\n        mock_chunk = MagicMock()\n        mock_chunk.page_content = \"Test content\"\n        mock_chunk.metadata = {\"page\": 1}\n\n        filename = \"guideline.pdf\"\n        embedding = [0.1] * 1536\n\n        record = {\n            \"title\": filename,\n            \"organization\": \"Unknown\",\n            \"publication_year\": \"2024\",\n            \"is_czech\": True,\n            \"content\": mock_chunk.page_content,\n            \"metadata\": {\n                \"source\": filename,\n                \"page\": mock_chunk.metadata.get(\"page\", 0),\n                **mock_chunk.metadata\n            },\n            \"embedding\": embedding\n        }\n\n        # Verify all required fields exist\n        assert \"title\" in record\n        assert \"organization\" in record\n        assert \"publication_year\" in record\n        assert \"is_czech\" in record\n        assert \"content\" in record\n        assert \"metadata\" in record\n        assert \"embedding\" in record\n\n        # Verify types\n        assert isinstance(record[\"title\"], str)\n        assert isinstance(record[\"publication_year\"], str)\n        assert isinstance(record[\"is_czech\"], bool)\n        assert isinstance(record[\"metadata\"], dict)\n        assert isinstance(record[\"embedding\"], list)\n        assert len(record[\"embedding\"]) == 1536\n\n    def test_metadata_contains_source_and_page(self):\n        \"\"\"Test that metadata includes source attribution.\"\"\"\n        mock_chunk = MagicMock()\n        mock_chunk.page_content = \"Content\"\n        mock_chunk.metadata = {\"page\": 5, \"extra_field\": \"value\"}\n\n        filename = \"test_guideline.pdf\"\n\n        metadata = {\n            \"source\": filename,\n            \"page\": mock_chunk.metadata.get(\"page\", 0),\n            **mock_chunk.metadata\n        }\n\n        assert metadata[\"source\"] == \"test_guideline.pdf\"\n        assert metadata[\"page\"] == 5\n        assert metadata[\"extra_field\"] == \"value\"\n",
        "last_modified": "2025-12-25T21:22:15.394790"
      },
      "task_intent": {
        "title": "001-complete-guidelines-rag-pdf-import",
        "description": "",
        "from_plan": false
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2025-12-25T01:36:14.318029",
  "last_updated": "2025-12-25T01:36:14.330878"
}