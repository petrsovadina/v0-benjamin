{
  "file_path": "backend/app/api/v1/endpoints/query.py",
  "main_branch_history": [],
  "task_views": {
    "001-complete-guidelines-rag-pdf-import": {
      "task_id": "001-complete-guidelines-rag-pdf-import",
      "branch_point": {
        "commit_hash": "d092d181e511c0ef7a36dcfd2dfe3f083cbae73e",
        "content": "",
        "timestamp": "2025-12-25T01:35:52.079046"
      },
      "worktree_state": {
        "content": "from fastapi import APIRouter, HTTPException, Depends, Request\nfrom fastapi.responses import StreamingResponse\nfrom backend.app.schemas.query import QueryRequest, QueryResponse\nfrom backend.app.core.graph import app as graph_app\nfrom backend.app.api.v1.deps import get_current_user\nfrom backend.app.core.database import get_supabase_client\nfrom langchain_core.messages import HumanMessage, AIMessage\nfrom typing import List, Dict, Any, Optional\nfrom pydantic import BaseModel\nimport json\nimport re\nfrom backend.services.logger import get_logger\nfrom backend.services.chat_history import ChatHistoryService\n\nlogger = get_logger(__name__)\nhistory_service = ChatHistoryService()\nrouter = APIRouter()\n\n# Schema for Stream (similar to main.py ChatRequest)\nclass StreamRequest(BaseModel):\n    message: str\n    history: Optional[list] = []\n    session_id: Optional[str] = None\n    user_id: Optional[str] = None\n\n@router.post(\"/\", response_model=QueryResponse)\nasync def create_query(\n    request: QueryRequest,\n    current_user: Dict[str, Any] = Depends(get_current_user)\n):\n    supabase = get_supabase_client()\n    query_id = None\n    \n    try:\n        # 1. Create Initial Query Record (Pending)\n        query_data = {\n            \"user_id\": current_user[\"id\"],\n            \"query_text\": request.query,\n            \"status\": \"processing\",\n            \"sources_requested\": [\"pubmed\", \"sukl\"] # Default for now\n        }\n        res = supabase.table(\"queries\").insert(query_data).execute()\n        if res.data:\n            query_id = res.data[0][\"id\"]\n        \n        # 2. Invoke AI Graph\n        # Convert history\n        messages = []\n        if request.items:\n            for msg in request.items:\n                if msg.get(\"role\") == \"user\":\n                    messages.append(HumanMessage(content=msg.get(\"content\", \"\")))\n                elif msg.get(\"role\") == \"assistant\":\n                    messages.append(AIMessage(content=msg.get(\"content\", \"\")))\n        messages.append(HumanMessage(content=request.query))\n        \n        inputs = {\"messages\": messages}\n        result = await graph_app.ainvoke(inputs)\n        \n        # Extract Results\n        final_answer = result.get(\"final_answer\", \"\")\n        query_type = result.get(\"query_type\", \"unknown\")\n        \n        # 3. Format Citations\n        citations_list = []\n        context = result.get(\"retrieved_context\", [])\n        \n        for idx, item in enumerate(context, 1):\n            source = item.get(\"source\")\n            data = item.get(\"data\", {})\n            \n            # Map based on source\n            cit = {\n                \"query_id\": query_id,\n                \"citation_order\": idx,\n                \"source_type\": source if source in ['pubmed', 'sukl', 'guidelines'] else 'other',\n                \"title\": data.get(\"title\") or data.get(\"name\") or \"Unknown Title\",\n                \"url\": data.get(\"url\") or data.get(\"spc_url\"),\n                \"snippet\": data.get(\"abstract\") or data.get(\"description\"),\n            }\n            \n            # Specific fields\n            if source == 'pubmed':\n                cit[\"pmid\"] = data.get(\"pmid\")\n                cit[\"doi\"] = data.get(\"doi\")\n                # Authors is list in data, but text[] in DB\n                if data.get(\"authors\"):\n                     cit[\"authors\"] = data.get(\"authors\")\n            elif source == 'sukl':\n                cit[\"external_id\"] = data.get(\"sukl_code\")\n            \n            citations_list.append(cit)\n            \n        # 4. Save Citations to DB\n        if citations_list and query_id:\n            supabase.table(\"citations\").insert(citations_list).execute()\n            \n        # 5. Update Query Record (Completed)\n        if query_id:\n            supabase.table(\"queries\").update({\n                \"response_text\": final_answer,\n                \"status\": \"completed\",\n                \"query_type\": query_type if query_type in ['quick', 'deep'] else 'quick', # Simple mapping for now\n                \"completed_at\": \"now()\",\n                \"sources_searched\": list(set(c[\"source_type\"] for c in citations_list))\n            }).eq(\"id\", query_id).execute()\n            \n        # Return Response\n        frontend_citations = []\n        for c in citations_list:\n            frontend_citations.append({\n                \"source\": c[\"source_type\"],\n                \"title\": c[\"title\"],\n                \"url\": c[\"url\"],\n                \"metadata\": c \n            })\n\n        return QueryResponse(\n            response=final_answer,\n            query_type=query_type,\n            citations=frontend_citations\n        )\n        \n    except Exception as e:\n        # Mark as failed if we created the record\n        if query_id:\n             supabase.table(\"queries\").update({\n                \"status\": \"failed\",\n                \"completed_at\": \"now()\"\n            }).eq(\"id\", query_id).execute()\n            \n        raise HTTPException(status_code=500, detail=str(e))\n\n@router.post(\"/stream\")\nasync def chat_stream_endpoint(body: StreamRequest):\n    \"\"\"\n    Streaming chat endpoint. Returns NDJSON chunks.\n    Format: {\"type\": \"token\", \"content\": \"...\"} or {\"type\": \"metadata\", \"data\": {...}}\n    \"\"\"\n    logger.info(\"Received chat stream request\")\n    \n    async def event_generator():\n        try:\n            from backend.agent_graph import app as agent_app\n            \n            inputs = {\"messages\": [HumanMessage(content=body.message)]}\n            citations = []\n            \n            # Save user message if session_id provided  \n            if body.session_id:\n                await history_service.add_message(\n                    session_id=body.session_id,\n                    role=\"user\",\n                    content=body.message\n                )\n\n            # Use astream_events to catch tool calls and tokens\n            accumulated_content = \"\"\n            async for event in agent_app.astream_events(inputs, version=\"v1\"):\n                kind = event[\"event\"]\n                \n                if kind == \"on_chat_model_stream\":\n                    content = event[\"data\"][\"chunk\"].content\n                    if content:\n                        if isinstance(content, str):\n                            accumulated_content += content\n                            yield json.dumps({\"type\": \"token\", \"content\": content}) + \"\\n\"\n                        elif isinstance(content, list):\n                            for block in content:\n                                if isinstance(block, str):\n                                    accumulated_content += block\n                                    yield json.dumps({\"type\": \"token\", \"content\": block}) + \"\\n\"\n                        else:\n                             chunk_str = str(content)\n                             accumulated_content += chunk_str\n                             yield json.dumps({\"type\": \"token\", \"content\": chunk_str}) + \"\\n\"\n                \n                elif kind == \"on_tool_end\":\n                    if event[\"name\"] == \"search_sukl_drugs\":\n                        try:\n                            output_str = str(event[\"data\"].get(\"output\", \"\"))\n                            urls = re.findall(r'https://www\\.sukl\\.cz/modules/medication/detail\\.php\\S+', output_str)\n                            if urls:\n                                url = urls[0]\n                            else:\n                                codes = re.findall(r'S\u00daKL:\\s*([0-9]+)', output_str)\n                                if codes:\n                                    code = codes[0]\n                                    url = f\"https://www.sukl.cz/modules/medication/detail.php?code={code}&tab=info\"\n                                else:\n                                    url = \"https://www.sukl.cz/modules/medication/search.php\"\n                        except Exception as e:\n                             logger.error(\"Error extracting S\u00daKL URL\", error=e)\n                             url = \"https://www.sukl.cz/modules/medication/search.php\"\n\n                        citations.append({\n                            \"id\": \"sukl-db\",\n                            \"type\": \"database\", \n                            \"value\": \"sukl\",\n                            \"title\": \"Datab\u00e1ze l\u00e9k\u016f S\u00daKL (2025)\",\n                            \"year\": 2025,\n                            \"url\": url\n                        })\n\n            # Send metadata\n            suggestions = []\n            if citations:\n                suggestions = [\"Jak\u00e9 je d\u00e1vkov\u00e1n\u00ed?\", \"Existuj\u00ed n\u011bjak\u00e9 interakce?\", \"Jak\u00e1 je cena?\"]\n            \n            metadata = {\n                \"citations\": citations,\n                \"suggestions\": suggestions\n            }\n            yield json.dumps({\"type\": \"metadata\", \"data\": metadata}) + \"\\n\"\n\n            # Save assistant response\n            if body.session_id:\n                await history_service.add_message(\n                    session_id=body.session_id,\n                    role=\"assistant\",\n                    content=accumulated_content,\n                    citations=citations\n                )\n\n        except Exception as e:\n            logger.error(\"Error in stream\", error=e)\n            yield json.dumps({\"type\": \"error\", \"content\": str(e)}) + \"\\n\"\n\n    return StreamingResponse(event_generator(), media_type=\"application/x-ndjson\")\n\n@router.get(\"/history\", response_model=List[Dict[str, Any]])\nasync def get_history(\n    current_user: Dict[str, Any] = Depends(get_current_user),\n    limit: int = 20,\n    offset: int = 0\n):\n    supabase = get_supabase_client()\n    try:\n        res = supabase.table(\"queries\")\\\n            .select(\"id, query_text, response_text, created_at, status, query_type\")\\\n            .eq(\"user_id\", current_user[\"id\"])\\\n            .order(\"created_at\", desc=True)\\\n            .limit(limit)\\\n            .range(offset, offset + limit - 1)\\\n            .execute()\n            \n        return res.data\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n",
        "last_modified": "2025-12-25T21:22:14.838958"
      },
      "task_intent": {
        "title": "001-complete-guidelines-rag-pdf-import",
        "description": "",
        "from_plan": false
      },
      "commits_behind_main": 0,
      "status": "active",
      "merged_at": null
    }
  },
  "created_at": "2025-12-25T01:36:12.648476",
  "last_updated": "2025-12-25T01:36:12.661407"
}