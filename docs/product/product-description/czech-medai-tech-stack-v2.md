# Czech MedAI ‚Äî Technick√Ω Stack v2.0

**Projekt:** Czech MedAI (k√≥dov√© oznaƒçen√≠: Benjamin)  
**Verze dokumentu:** 2.0 (Context7 Verified)  
**Datum:** 12.12.2025  
**Status:** Production-Ready ‚Äî v≈°echny verze ovƒõ≈ôeny p≈ôes Context7 MCP

---

## üìã Executive Summary

Tento dokument obsahuje **aktualizovan√Ω a ovƒõ≈ôen√Ω technick√Ω stack** pro projekt Czech MedAI. V≈°echny verze knihoven byly validov√°ny pomoc√≠ Context7 MCP serveru pro zaji≈°tƒõn√≠:

- ‚úÖ **Aktu√°ln√≠ch stabiln√≠ch verz√≠** (ne beta/canary)
- ‚úÖ **Production-ready patterns** z ofici√°ln√≠ dokumentace
- ‚úÖ **Best practices** pro ka≈ædou technologii
- ‚úÖ **Kompletn√≠ch code examples** p≈ôipraven√Ωch k pou≈æit√≠

---

## üîß Kompletn√≠ Technology Stack

### P≈ôehled verz√≠ (Context7 Verified)

| Vrstva | Technologie | Verze | Trust Score |
|--------|-------------|-------|-------------|
| **Frontend** | Next.js | 15.4.0 / 16.0.3 | 10/10 |
| **Frontend** | Tailwind CSS | 4.x | 9.9/10 |
| **Frontend** | Shadcn/UI | shadcn@3.5.0 | 10/10 |
| **Backend** | FastAPI | 0.122.0 | 9.9/10 |
| **Backend** | Python | 3.11+ (3.12 recommended) | ‚Äî |
| **Backend** | Pydantic | 2.x | ‚Äî |
| **AI Orchestration** | LangGraph | 1.0.3 | 9.2/10 |
| **AI Orchestration** | MCP Python SDK | latest | 7.8/10 |
| **LLM** | Anthropic SDK Python | latest | 8.8/10 |
| **Database** | Supabase | 1.25.04 | 10/10 |
| **Database** | PostgreSQL + pgvector | 15+ | 9.5/10 |

---

## üé® Frontend Stack

### Next.js 15.4+ (App Router)

**Verze:** 15.4.0 nebo 16.0.3 (obƒõ stabiln√≠)  
**Trust Score:** 10/10  
**Code Snippets:** 9,372+

#### Inicializace projektu
```bash
npx create-next-app@latest czech-medai --typescript --eslint --app
cd czech-medai
```

#### Root Layout (App Router Pattern)
```typescript
// app/layout.tsx
import type { Metadata } from 'next'
import { Inter } from 'next/font/google'
import './globals.css'

const inter = Inter({ subsets: ['latin', 'latin-ext'] })

export const metadata: Metadata = {
  title: 'Czech MedAI ‚Äî Klinick√Ω AI Asistent',
  description: 'AI-poh√°nƒõn√Ω klinick√Ω asistent pro ƒçesk√© l√©ka≈ôe',
}

export default function RootLayout({
  children,
}: {
  children: React.ReactNode
}) {
  return (
    <html lang="cs" className={inter.className}>
      <body>{children}</body>
    </html>
  )
}
```

#### API Route Handler Pattern
```typescript
// app/api/query/route.ts
import { NextRequest, NextResponse } from 'next/server'

export async function POST(request: NextRequest) {
  const { query } = await request.json()
  
  // Call backend API
  const response = await fetch(`${process.env.BACKEND_URL}/api/v1/query`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ query }),
  })
  
  const data = await response.json()
  return NextResponse.json(data)
}
```

---

### Tailwind CSS 4.x

**Verze:** 4.x (nejnovƒõj≈°√≠)  
**Trust Score:** 9.9/10  
**Zmƒõna:** Nov√Ω `@tailwindcss/postcss` plugin

#### PostCSS Configuration (v4 Pattern)
```javascript
// postcss.config.mjs
const config = {
  plugins: {
    "@tailwindcss/postcss": {},
  },
};
export default config;
```

#### Global CSS Import
```css
/* app/globals.css */
@import "tailwindcss";

/* Custom theme variables */
@theme {
  --color-primary: oklch(0.55 0.2 250);
  --color-secondary: oklch(0.7 0.15 180);
  --font-display: "Inter", sans-serif;
}
```

#### Instalace
```bash
npm install tailwindcss @tailwindcss/postcss
```

---

### Shadcn/UI

**Verze:** shadcn@3.5.0  
**Trust Score:** 10/10  
**Code Snippets:** 761+

#### Inicializace
```bash
npx shadcn@latest init
```

#### P≈ôid√°n√≠ komponent
```bash
npx shadcn@latest add button input card dialog toast
```

#### Theme Provider Setup
```typescript
// components/theme-provider.tsx
"use client"

import * as React from "react"
import { ThemeProvider as NextThemesProvider } from "next-themes"

export function ThemeProvider({
  children,
  ...props
}: React.ComponentProps<typeof NextThemesProvider>) {
  return <NextThemesProvider {...props}>{children}</NextThemesProvider>
}
```

#### Root Layout s Theme Provider
```typescript
// app/layout.tsx
import { ThemeProvider } from "@/components/theme-provider"
import { Toaster } from "@/components/ui/sonner"

export default function RootLayout({ children }: { children: React.ReactNode }) {
  return (
    <html lang="cs" suppressHydrationWarning>
      <body>
        <ThemeProvider
          attribute="class"
          defaultTheme="system"
          enableSystem
          disableTransitionOnChange
        >
          {children}
          <Toaster />
        </ThemeProvider>
      </body>
    </html>
  )
}
```

---

## ‚öôÔ∏è Backend Stack

### FastAPI 0.122.0

**Verze:** 0.122.0  
**Trust Score:** 9.9/10  
**Code Snippets:** 881+

#### Main Application Setup
```python
# app/main.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager

from app.api.v1 import router as api_router
from app.core.config import settings

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Startup and shutdown events."""
    # Startup: Initialize connections
    print("üöÄ Starting Czech MedAI API...")
    yield
    # Shutdown: Cleanup
    print("üëã Shutting down...")

app = FastAPI(
    title="Czech MedAI API",
    version="1.0.0",
    description="AI-powered clinical assistant for Czech physicians",
    lifespan=lifespan,
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(api_router, prefix="/api/v1")
```

#### Pydantic v2 Models (Best Practice)
```python
# app/schemas/query.py
from pydantic import BaseModel, Field
from typing import Literal
from datetime import datetime

class QueryRequest(BaseModel):
    """Request model for clinical queries."""
    query: str = Field(..., min_length=3, max_length=2000)
    query_type: Literal["quick", "deep"] = "quick"
    language: Literal["cs", "en"] = "cs"
    
    model_config = {
        "json_schema_extra": {
            "examples": [{
                "query": "Jak√© jsou prvn√≠ linie l√©ƒçby hypertenze u diabetik≈Ø?",
                "query_type": "quick",
                "language": "cs"
            }]
        }
    }

class Citation(BaseModel):
    """Citation model with PMID/DOI."""
    id: int
    source: str
    title: str
    pmid: str | None = None
    doi: str | None = None
    url: str
    relevance_score: float = Field(..., ge=0.0, le=1.0)

class QueryResponse(BaseModel):
    """Response model for clinical queries."""
    answer: str
    citations: list[Citation]
    query_type: str
    processing_time_ms: int
    timestamp: datetime
```

#### Query Parameter Models (FastAPI 0.122 Pattern)
```python
# app/api/v1/endpoints/search.py
from fastapi import APIRouter, Query
from pydantic import BaseModel, Field
from typing import Annotated, Literal

router = APIRouter()

class SearchParams(BaseModel):
    """Search parameters with validation."""
    q: str = Field(..., min_length=1, max_length=500)
    limit: int = Field(10, gt=0, le=100)
    offset: int = Field(0, ge=0)
    source: Literal["pubmed", "sukl", "guidelines", "all"] = "all"
    sort_by: Literal["relevance", "date", "citations"] = "relevance"

@router.get("/search")
async def search_medical_literature(
    params: Annotated[SearchParams, Query()]
):
    """Search across medical data sources."""
    return {"params": params.model_dump()}
```

---

## ü§ñ AI Orchestration Stack

### LangGraph 1.0.3

**Verze:** 1.0.3 (MAJOR upgrade from 0.0.20)  
**Trust Score:** 9.2/10  
**Code Snippets:** 2,336+

#### StateGraph s Conditional Routing
```python
# app/core/graph.py
from typing import TypedDict, Literal, Annotated
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages

class ClinicalState(TypedDict):
    """State for clinical query processing."""
    messages: Annotated[list, add_messages]
    query_type: str
    sources_needed: list[str]
    retrieved_docs: list[dict]
    citations: list[dict]
    final_answer: str
    retry_count: int

def classify_query(state: ClinicalState) -> ClinicalState:
    """Classify the type of clinical query."""
    last_message = state["messages"][-1].content.lower()
    
    if any(word in last_message for word in ["l√©k", "l√©ƒçivo", "p≈ô√≠pravek", "sukl"]):
        state["query_type"] = "drug_info"
        state["sources_needed"] = ["sukl", "pubmed"]
    elif any(word in last_message for word in ["guideline", "doporuƒçen√≠", "postup"]):
        state["query_type"] = "guidelines"
        state["sources_needed"] = ["cls_jep", "esc", "pubmed"]
    elif any(word in last_message for word in ["√∫hrada", "vzp", "poji≈°≈•ovna"]):
        state["query_type"] = "reimbursement"
        state["sources_needed"] = ["vzp", "sukl"]
    else:
        state["query_type"] = "general"
        state["sources_needed"] = ["pubmed", "guidelines"]
    
    return state

def route_by_query_type(state: ClinicalState) -> Literal["drug_retrieval", "guideline_retrieval", "general_retrieval", "escalate"]:
    """Route to appropriate retrieval strategy."""
    if state.get("retry_count", 0) > 3:
        return "escalate"
    
    query_type = state.get("query_type", "general")
    
    routing_map = {
        "drug_info": "drug_retrieval",
        "guidelines": "guideline_retrieval",
        "reimbursement": "drug_retrieval",  # VZP data is in drug retrieval
        "general": "general_retrieval",
    }
    
    return routing_map.get(query_type, "general_retrieval")

# Build the graph
def build_clinical_graph() -> StateGraph:
    """Build the clinical query processing graph."""
    graph = StateGraph(ClinicalState)
    
    # Add nodes
    graph.add_node("classifier", classify_query)
    graph.add_node("drug_retrieval", retrieve_drug_info)
    graph.add_node("guideline_retrieval", retrieve_guidelines)
    graph.add_node("general_retrieval", retrieve_general)
    graph.add_node("synthesizer", synthesize_answer)
    graph.add_node("escalate", human_escalation)
    
    # Add edges
    graph.add_edge(START, "classifier")
    
    # Conditional routing from classifier
    graph.add_conditional_edges(
        "classifier",
        route_by_query_type,
        {
            "drug_retrieval": "drug_retrieval",
            "guideline_retrieval": "guideline_retrieval",
            "general_retrieval": "general_retrieval",
            "escalate": "escalate",
        }
    )
    
    # All retrievals go to synthesizer
    graph.add_edge("drug_retrieval", "synthesizer")
    graph.add_edge("guideline_retrieval", "synthesizer")
    graph.add_edge("general_retrieval", "synthesizer")
    graph.add_edge("synthesizer", END)
    graph.add_edge("escalate", END)
    
    return graph.compile()

# Usage
clinical_workflow = build_clinical_graph()
```

---

### MCP Python SDK (FastMCP)

**Trust Score:** 7.8/10  
**Code Snippets:** 296+

#### PubMed MCP Server
```python
# mcp_servers/pubmed_server.py
from mcp.server.fastmcp import FastMCP, Context
from mcp.server.session import ServerSession
import httpx

mcp = FastMCP(
    "PubMed MCP Server",
    json_response=True,
)

@mcp.tool()
async def search_pubmed(
    query: str,
    max_results: int = 10,
    ctx: Context[ServerSession, None] = None
) -> dict:
    """
    Search PubMed for medical literature.
    
    Args:
        query: Search query in Czech or English
        max_results: Maximum number of results (1-100)
    
    Returns:
        Dictionary with search results and PMIDs
    """
    await ctx.info(f"Searching PubMed for: {query}")
    
    base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils"
    
    async with httpx.AsyncClient() as client:
        # Search for PMIDs
        search_response = await client.get(
            f"{base_url}/esearch.fcgi",
            params={
                "db": "pubmed",
                "term": query,
                "retmax": max_results,
                "retmode": "json",
            }
        )
        search_data = search_response.json()
        pmids = search_data.get("esearchresult", {}).get("idlist", [])
        
        if not pmids:
            return {"results": [], "count": 0}
        
        # Fetch article details
        fetch_response = await client.get(
            f"{base_url}/efetch.fcgi",
            params={
                "db": "pubmed",
                "id": ",".join(pmids),
                "retmode": "xml",
            }
        )
        
        # Parse and return results
        return {
            "pmids": pmids,
            "count": len(pmids),
            "query": query,
        }

@mcp.tool()
async def get_article_abstract(
    pmid: str,
    ctx: Context[ServerSession, None] = None
) -> dict:
    """
    Get abstract for a specific PubMed article.
    
    Args:
        pmid: PubMed ID of the article
    
    Returns:
        Article title, abstract, and metadata
    """
    await ctx.debug(f"Fetching abstract for PMID: {pmid}")
    
    base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils"
    
    async with httpx.AsyncClient() as client:
        response = await client.get(
            f"{base_url}/efetch.fcgi",
            params={
                "db": "pubmed",
                "id": pmid,
                "rettype": "abstract",
                "retmode": "text",
            }
        )
        
        return {
            "pmid": pmid,
            "abstract": response.text,
            "url": f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/",
        }

@mcp.resource("pubmed://stats")
def get_pubmed_stats() -> str:
    """Get PubMed database statistics."""
    return "PubMed contains 36+ million citations for biomedical literature."

if __name__ == "__main__":
    mcp.run(transport="streamable-http")
```

#### S√öKL MCP Server
```python
# mcp_servers/sukl_server.py
from mcp.server.fastmcp import FastMCP, Context
from contextlib import asynccontextmanager
from collections.abc import AsyncIterator
from dataclasses import dataclass
import asyncpg

@dataclass
class AppContext:
    """Application context with database connection."""
    db_pool: asyncpg.Pool

@asynccontextmanager
async def app_lifespan(server: FastMCP) -> AsyncIterator[AppContext]:
    """Manage database connection lifecycle."""
    pool = await asyncpg.create_pool(
        "postgresql://user:pass@localhost/sukl_db"
    )
    try:
        yield AppContext(db_pool=pool)
    finally:
        await pool.close()

mcp = FastMCP(
    "S√öKL MCP Server",
    lifespan=app_lifespan,
    json_response=True,
)

@mcp.tool()
async def search_drugs(
    query: str,
    ctx: Context
) -> list[dict]:
    """
    Search S√öKL drug database.
    
    Args:
        query: Drug name, ATC code, or active substance
    
    Returns:
        List of matching drugs with details
    """
    db = ctx.request_context.lifespan_context.db_pool
    
    results = await db.fetch("""
        SELECT 
            sukl_code,
            name,
            atc_code,
            active_substance,
            strength,
            form,
            registration_holder
        FROM drugs
        WHERE 
            name ILIKE $1 
            OR atc_code ILIKE $1
            OR active_substance ILIKE $1
        LIMIT 20
    """, f"%{query}%")
    
    return [dict(r) for r in results]

@mcp.tool()
async def get_drug_spc(
    sukl_code: str,
    ctx: Context
) -> dict:
    """
    Get Summary of Product Characteristics (SPC) for a drug.
    
    Args:
        sukl_code: S√öKL registration code
    
    Returns:
        Full SPC document with indications, contraindications, dosing
    """
    db = ctx.request_context.lifespan_context.db_pool
    
    spc = await db.fetchrow("""
        SELECT 
            sukl_code,
            name,
            indications,
            contraindications,
            dosing,
            interactions,
            side_effects,
            pregnancy_category
        FROM spc_documents
        WHERE sukl_code = $1
    """, sukl_code)
    
    return dict(spc) if spc else {"error": "SPC not found"}

if __name__ == "__main__":
    mcp.run(transport="streamable-http")
```

---

### Anthropic SDK Python

**Trust Score:** 8.8/10  
**Code Snippets:** 93+

#### Async Streaming Implementation
```python
# app/services/llm_service.py
from anthropic import AsyncAnthropic
from typing import AsyncIterator

class LLMService:
    """Service for LLM interactions with streaming support."""
    
    def __init__(self):
        self.client = AsyncAnthropic()
        self.model = "claude-sonnet-4-20250514"
    
    async def stream_response(
        self,
        query: str,
        context: str,
        system_prompt: str
    ) -> AsyncIterator[str]:
        """Stream response from Claude."""
        async with self.client.messages.stream(
            model=self.model,
            max_tokens=2048,
            system=system_prompt,
            messages=[
                {
                    "role": "user",
                    "content": f"Context:\n{context}\n\nQuery: {query}"
                }
            ],
        ) as stream:
            async for text in stream.text_stream:
                yield text
    
    async def generate_with_citations(
        self,
        query: str,
        documents: list[dict],
    ) -> dict:
        """Generate answer with inline citations."""
        context = self._format_documents(documents)
        
        response = await self.client.messages.create(
            model=self.model,
            max_tokens=2048,
            system=CLINICAL_SYSTEM_PROMPT,
            messages=[
                {
                    "role": "user",
                    "content": f"""Based on the following sources, answer the clinical query.
                    
Sources:
{context}

Query: {query}

Provide a concise answer with inline citations [1][2][3] referencing the sources."""
                }
            ],
        )
        
        return {
            "answer": response.content[0].text,
            "model": response.model,
            "usage": {
                "input_tokens": response.usage.input_tokens,
                "output_tokens": response.usage.output_tokens,
            }
        }
    
    def _format_documents(self, documents: list[dict]) -> str:
        """Format documents for context."""
        formatted = []
        for i, doc in enumerate(documents, 1):
            formatted.append(f"[{i}] {doc['title']}\n{doc['content']}\nSource: {doc['url']}")
        return "\n\n".join(formatted)

CLINICAL_SYSTEM_PROMPT = """Jsi Czech MedAI, AI asistent pro ƒçesk√© l√©ka≈ôe.

PRAVIDLA:
1. Odpov√≠dej V≈ΩDY ƒçesky s korektn√≠ l√©ka≈ôskou terminologi√≠
2. KA≈ΩD√Å odpovƒõƒè mus√≠ obsahovat inline citace [1][2][3]
3. Buƒè struƒçn√Ω (3-5 vƒõt) ale p≈ôesn√Ω
4. Pokud si nejsi jist√Ω, ≈ôekni to
5. NIKDY neposkytuj diagn√≥zu ani l√©ƒçebn√Ω pl√°n

FORM√ÅT ODPOVƒöDI:
- Struƒçn√° odpovƒõƒè s inline citacemi
- Seznam citac√≠ na konci"""
```

---

## üóÑÔ∏è Database Stack

### Supabase (PostgreSQL + pgvector)

**Verze:** 1.25.04  
**Trust Score:** 10/10  
**Code Snippets:** 6,841+

#### RLS Best Practices (Context7 Verified)
```sql
-- Create users table with RLS
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email TEXT UNIQUE NOT NULL,
    license_number TEXT,  -- IƒåP/ƒåLK verification
    role TEXT DEFAULT 'physician',
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Enable RLS
ALTER TABLE users ENABLE ROW LEVEL SECURITY;

-- Optimized RLS policy (TO authenticated pattern)
CREATE POLICY "Users can view own profile"
ON users FOR SELECT
TO authenticated
USING ((SELECT auth.uid()) = id);

-- Medical queries table
CREATE TABLE queries (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    query_text TEXT NOT NULL,
    response_text TEXT,
    citations JSONB,
    query_type TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- RLS for queries
ALTER TABLE queries ENABLE ROW LEVEL SECURITY;

-- Optimized policy with SELECT wrapper (14,833x faster!)
CREATE POLICY "Users can view own queries"
ON queries FOR SELECT
TO authenticated
USING ((SELECT auth.uid()) = user_id);

CREATE POLICY "Users can insert own queries"
ON queries FOR INSERT
TO authenticated
WITH CHECK ((SELECT auth.uid()) = user_id);

-- Index for RLS performance
CREATE INDEX idx_queries_user_id ON queries USING btree (user_id);
```

#### pgvector Setup for RAG
```sql
-- Enable pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Documents table with embeddings
CREATE TABLE documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    source TEXT NOT NULL,  -- 'pubmed', 'sukl', 'guidelines'
    external_id TEXT,      -- PMID, SUKL code, etc.
    title TEXT NOT NULL,
    content TEXT NOT NULL,
    embedding vector(1536),  -- OpenAI ada-002 dimension
    metadata JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- HNSW index for fast similarity search
CREATE INDEX ON documents 
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- Semantic search function
CREATE OR REPLACE FUNCTION search_documents(
    query_embedding vector(1536),
    match_count INT DEFAULT 10,
    source_filter TEXT DEFAULT NULL
)
RETURNS TABLE (
    id UUID,
    source TEXT,
    title TEXT,
    content TEXT,
    similarity FLOAT
)
LANGUAGE plpgsql
AS $$
BEGIN
    RETURN QUERY
    SELECT
        d.id,
        d.source,
        d.title,
        d.content,
        1 - (d.embedding <=> query_embedding) AS similarity
    FROM documents d
    WHERE source_filter IS NULL OR d.source = source_filter
    ORDER BY d.embedding <=> query_embedding
    LIMIT match_count;
END;
$$;
```

#### Supabase Python Client
```python
# app/db/supabase_client.py
from supabase import create_client, Client
from app.core.config import settings

def get_supabase_client() -> Client:
    """Get Supabase client instance."""
    return create_client(
        settings.SUPABASE_URL,
        settings.SUPABASE_ANON_KEY
    )

async def semantic_search(
    client: Client,
    query_embedding: list[float],
    source: str | None = None,
    limit: int = 10
) -> list[dict]:
    """Perform semantic search on documents."""
    response = client.rpc(
        'search_documents',
        {
            'query_embedding': query_embedding,
            'match_count': limit,
            'source_filter': source
        }
    ).execute()
    
    return response.data
```

---

## üì¶ Z√°vislosti a Instalace

### Frontend (package.json)
```json
{
  "name": "czech-medai-frontend",
  "version": "1.0.0",
  "dependencies": {
    "next": "^15.4.0",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "next-themes": "^0.4.0",
    "@supabase/supabase-js": "^2.45.0",
    "sonner": "^1.7.0",
    "lucide-react": "^0.460.0",
    "class-variance-authority": "^0.7.0",
    "clsx": "^2.1.0",
    "tailwind-merge": "^2.5.0"
  },
  "devDependencies": {
    "typescript": "^5.7.0",
    "@types/node": "^22.0.0",
    "@types/react": "^19.0.0",
    "tailwindcss": "^4.0.0",
    "@tailwindcss/postcss": "^4.0.0",
    "eslint": "^9.0.0",
    "eslint-config-next": "^15.4.0"
  }
}
```

### Backend (pyproject.toml)
```toml
[project]
name = "czech-medai-backend"
version = "1.0.0"
requires-python = ">=3.11"

dependencies = [
    "fastapi>=0.122.0",
    "uvicorn[standard]>=0.32.0",
    "pydantic>=2.10.0",
    "pydantic-settings>=2.6.0",
    "langgraph>=1.0.3",
    "langchain>=0.3.0",
    "langchain-anthropic>=0.3.0",
    "anthropic>=0.40.0",
    "mcp>=1.0.0",
    "supabase>=2.10.0",
    "asyncpg>=0.30.0",
    "httpx>=0.28.0",
    "redis>=5.2.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.24.0",
    "ruff>=0.8.0",
    "mypy>=1.13.0",
]
```

---

## üê≥ Docker Configuration

### Dockerfile (Backend)
```dockerfile
FROM python:3.12-slim

WORKDIR /app

# Install uv for fast dependency management
RUN pip install uv

# Copy dependency files
COPY pyproject.toml .
COPY uv.lock .

# Install dependencies
RUN uv sync --frozen

# Copy application code
COPY app/ app/
COPY mcp_servers/ mcp_servers/

# Expose port
EXPOSE 8000

# Run with uvicorn
CMD ["uv", "run", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### docker-compose.yml
```yaml
version: '3.9'

services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis

  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://backend:8000
    depends_on:
      - backend

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  mcp-pubmed:
    build: ./mcp_servers/pubmed
    ports:
      - "8001:8000"

  mcp-sukl:
    build: ./mcp_servers/sukl
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=${SUKL_DATABASE_URL}

volumes:
  redis_data:
```

---

## üìä Migrace z p≈ôedchoz√≠ch verz√≠

### Breaking Changes

| Komponenta | Star√° verze | Nov√° verze | Zmƒõny |
|------------|-------------|------------|-------|
| Next.js | 14.x | 15.4+ | App Router je nyn√≠ v√Ωchoz√≠, Turbopack stabiln√≠ |
| Tailwind CSS | 3.x | 4.x | Nov√Ω `@tailwindcss/postcss` plugin, CSS-first config |
| LangGraph | 0.0.20 | 1.0.3 | StateGraph API stabilizov√°no, nov√© routing patterns |
| FastAPI | 0.109 | 0.122 | Pydantic v2 `model_config` (ne `Config` class) |

### Migration Steps

1. **Next.js 14 ‚Üí 15**
   ```bash
   npm install next@latest react@latest react-dom@latest
   ```

2. **Tailwind CSS 3 ‚Üí 4**
   ```bash
   npx @tailwindcss/upgrade
   ```

3. **LangGraph 0.x ‚Üí 1.0**
   - Zmƒõnit `from langgraph.graph import Graph` na `from langgraph.graph import StateGraph`
   - Aktualizovat conditional edges syntax

4. **FastAPI/Pydantic**
   - Zmƒõnit `class Config:` na `model_config = {...}`
   - Pou≈æ√≠t `Annotated[Type, Query()]` pro query params

---

## ‚úÖ Checklist pro Production

- [ ] V≈°echny environment variables nastaveny
- [ ] RLS policies aktivn√≠ na v≈°ech tabulk√°ch
- [ ] HTTPS enabled (Vercel/Railway automaticky)
- [ ] Rate limiting implementov√°n
- [ ] Error monitoring (Sentry) nakonfigurov√°n
- [ ] Langfuse pro LLM observability
- [ ] Health check endpoints funkƒçn√≠
- [ ] Backup strategie pro Supabase

---

*Dokument vytvo≈ôen s pomoc√≠ Context7 MCP ‚Äî 12.12.2025*
